# ğŸš€ è‡ªé€‚åº”å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ï¼šåŠ¨æ€èµ„æºåˆ†é…ç³»ç»Ÿ

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-orange.svg)](https://pytorch.org/)
[![Gymnasium](https://img.shields.io/badge/Gymnasium-0.29+-green.svg)](https://gymnasium.farama.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªåŸºäº**æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDRLï¼‰**çš„åŠ¨æ€èµ„æºåˆ†é…è§£å†³æ–¹æ¡ˆï¼Œé‡‡ç”¨**æ·±åº¦Qç½‘ç»œï¼ˆDQNï¼‰**å’Œ**åŒé‡DQN**ç®—æ³•ã€‚ç³»ç»Ÿèƒ½å¤Ÿå®æ—¶ä¼˜åŒ–å¤šä¸ªç½‘ç»œæœåŠ¡çš„å¸¦å®½åˆ†é…ï¼Œå±•ç¤ºäº†ç°ä»£å¼ºåŒ–å­¦ä¹ æŠ€æœ¯åœ¨å®é™…èµ„æºç®¡ç†é—®é¢˜ä¸­çš„åº”ç”¨ã€‚

### ğŸŒŸ æ ¸å¿ƒåˆ›æ–°ç‚¹
- **ğŸ—ï¸ åˆ›æ–°ç¯å¢ƒè®¾è®¡**ï¼šåŸºäºOpenAI Gymnasiumçš„è‡ªå®šä¹‰åŠ¨æ€ç½‘ç»œæµé‡ç®¡ç†ç¯å¢ƒ
- **âš–ï¸ ç®—æ³•å¯¹æ¯”ç ”ç©¶**ï¼šDQNä¸Double DQNçš„å¹¶è¡Œå®ç°ï¼Œæ·±å…¥åˆ†æè¿‡ä¼°è®¡åå·®é—®é¢˜
- **ğŸŒ å®é™…åº”ç”¨å¯¼å‘**ï¼šè§£å†³ç½‘ç»œèµ„æºåˆ†é…å’ŒQoSä¼˜åŒ–çš„å®é™…æŒ‘æˆ˜
- **ğŸ“Š å®Œæ•´è¯„ä¼°æ¡†æ¶**ï¼šæ¶µç›–æµ‹è¯•ã€è®­ç»ƒå’Œåˆ†æçš„å®Œæ•´æµæ°´çº¿
- **ğŸ® æ™ºèƒ½å†³ç­–ç³»ç»Ÿ**ï¼šå®æ—¶å“åº”åŠ¨æ€éœ€æ±‚å˜åŒ–çš„è‡ªé€‚åº”åˆ†é…ç­–ç•¥

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

### æ ¸å¿ƒç»„ä»¶

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ environments/          # è‡ªå®šä¹‰Gymnasiumç¯å¢ƒ
â”‚   â”‚   â””â”€â”€ network_traffic_env.py    # åŠ¨æ€æµé‡ç®¡ç†ç¯å¢ƒ
â”‚   â”œâ”€â”€ agents/               # å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“å®ç°
â”‚   â”‚   â”œâ”€â”€ dqn_agent.py     # æ ‡å‡†DQNæ™ºèƒ½ä½“
â”‚   â”‚   â””â”€â”€ double_dqn_agent.py      # åŒé‡DQNæ™ºèƒ½ä½“
â”‚   â”œâ”€â”€ models/               # ç¥ç»ç½‘ç»œæ¶æ„
â”‚   â”‚   â””â”€â”€ dqn_model.py     # æ·±åº¦Qç½‘ç»œæ¨¡å‹ï¼ˆPyTorchï¼‰
â”‚   â””â”€â”€ utils/                # å·¥å…·å‡½æ•°å’Œç±»
â”‚       â”œâ”€â”€ replay_buffer.py  # ç»éªŒå›æ”¾å®ç°
â”‚       â””â”€â”€ plotters.py       # å¯è§†åŒ–å’Œåˆ†æå·¥å…·
â”œâ”€â”€ notebooks/                # Jupyteråˆ†æç¬”è®°æœ¬
â”‚   â””â”€â”€ experiment_analysis.ipynb    # æ ¸å¿ƒå®éªŒåˆ†æ
â”œâ”€â”€ main_train.py            # è®­ç»ƒè„šæœ¬ï¼ˆCLIæ¥å£ï¼‰
â”œâ”€â”€ main_evaluate.py         # è¯„ä¼°å’Œå¯¹æ¯”è„šæœ¬
â””â”€â”€ test_components.py       # ç»¼åˆæµ‹è¯•å¥—ä»¶
```

## ğŸŒŸ æ ¸å¿ƒç‰¹æ€§

### ç¯å¢ƒï¼šåŠ¨æ€ç½‘ç»œæµé‡ç®¡ç†å™¨
- **ğŸ¯ å¤šæœåŠ¡æ¶æ„**ï¼šç®¡ç†4ç§æœåŠ¡ç±»å‹ï¼ˆè§†é¢‘ã€æ¸¸æˆã€ä¸‹è½½ã€ç½‘é¡µæµè§ˆï¼‰
- **ğŸ“ˆ åŠ¨æ€éœ€æ±‚ä»¿çœŸ**ï¼šå®æ—¶æ³¢åŠ¨çš„éœ€æ±‚æ¨¡å¼
- **ğŸ§  æ™ºèƒ½å¥–åŠ±è®¾è®¡**ï¼šå¯¹æœªæ»¡è¶³éœ€æ±‚å’Œå¸¦å®½æµªè´¹è¿›è¡Œæƒ©ç½šï¼Œå¯¹æœ€ä¼˜åˆ†é…è¿›è¡Œå¥–åŠ±
- **ğŸ”¢ çŠ¶æ€ç©ºé—´**ï¼š8ç»´è¿ç»­ç©ºé—´ï¼ˆéœ€æ±‚+å½“å‰åˆ†é…ï¼‰
- **âš¡ åŠ¨ä½œç©ºé—´**ï¼š5ä¸ªç¦»æ•£åŠ¨ä½œç”¨äºå¸¦å®½è°ƒæ•´

### æ™ºèƒ½ä½“
- **ğŸ¤– DQNæ™ºèƒ½ä½“**ï¼šç»å…¸æ·±åº¦Qç½‘ç»œï¼Œå…·å¤‡ç»éªŒå›æ”¾å’Œç›®æ ‡ç½‘ç»œ
- **ğŸ”„ åŒé‡DQNæ™ºèƒ½ä½“**ï¼šå¢å¼ºç‰ˆæœ¬ï¼Œè§£å†³Qå€¼è¿‡ä¼°è®¡åå·®
- **ğŸ› ï¸ å…±äº«ç‰¹æ€§**ï¼š
  - ç»éªŒå›æ”¾ç¼“å†²åŒºï¼ˆå¯é…ç½®å¤§å°ï¼‰
  - è½¯æ›´æ–°ç›®æ ‡ç½‘ç»œ
  - Îµ-è´ªå©ªæ¢ç´¢ç­–ç•¥ï¼ˆå¸¦è¡°å‡ï¼‰
  - GPUåŠ é€Ÿæ”¯æŒ
  - æ¨¡å‹ä¿å­˜/åŠ è½½åŠŸèƒ½

### è®­ç»ƒä¸è¯„ä¼°
- **ğŸ”§ çµæ´»è®­ç»ƒæµæ°´çº¿**ï¼šé€šè¿‡å‘½ä»¤è¡Œç•Œé¢é…ç½®è¶…å‚æ•°
- **ğŸ“Š å®æ—¶ç›‘æ§**ï¼šè¿›åº¦è·Ÿè¸ªå’Œå¯è§†åŒ–
- **ğŸ“ˆ ç»¼åˆè¯„ä¼°**ï¼šæ€§èƒ½æŒ‡æ ‡ã€å¯¹æ¯”åˆ†æå’Œç»Ÿè®¡æ˜¾è‘—æ€§æµ‹è¯•
- **ğŸ¨ å¯è§†åŒ–å¥—ä»¶**ï¼šè®­ç»ƒæ›²çº¿ã€epsilonè¡°å‡ã€ç¯å¢ƒæŒ‡æ ‡å’Œå¯¹æ¯”å›¾è¡¨

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚
```bash
Python 3.8+
pip åŒ…ç®¡ç†å™¨
```

### å®‰è£…æ­¥éª¤
```bash
# å…‹éš†ä»“åº“
git clone https://github.com/PrescottClub/Adaptive-RL-Agent-for-Dynamic-Resource-Allocation.git
cd Adaptive-RL-Agent-for-Dynamic-Resource-Allocation

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# éªŒè¯å®‰è£…
python test_components.py
```

### åŸºæœ¬ä½¿ç”¨

#### 1. è®­ç»ƒDQNæ™ºèƒ½ä½“
```bash
python main_train.py --agent dqn --episodes 2000 --save_every 500
```

#### 2. è®­ç»ƒåŒé‡DQNæ™ºèƒ½ä½“
```bash
python main_train.py --agent double_dqn --episodes 2000 --save_every 500
```

#### 3. è¯„ä¼°å•ä¸ªæ™ºèƒ½ä½“
```bash
python main_evaluate.py --mode single --agent dqn --model_path models/dqn_final.pth
```

#### 4. å¯¹æ¯”æ™ºèƒ½ä½“æ€§èƒ½
```bash
python main_evaluate.py --mode compare --dqn_model models/dqn_final.pth --ddqn_model models/double_dqn_final.pth
```

#### 5. ğŸ¯ æ ¸å¿ƒå±•ç¤ºï¼šè¿è¡Œå®éªŒåˆ†æ
```bash
# å¯åŠ¨Jupyter Notebook
jupyter notebook

# æ‰“å¼€å¹¶è¿è¡Œ notebooks/experiment_analysis.ipynb
# è¿™æ˜¯é¡¹ç›®çš„æ ¸å¿ƒå±•ç¤ºæ–‡ä»¶ï¼ŒåŒ…å«å®Œæ•´çš„å®éªŒåˆ†æå’Œå¯è§†åŒ–
```

## ğŸ“Š è¯¦ç»†ä½¿ç”¨è¯´æ˜

### è®­ç»ƒé…ç½®
```bash
python main_train.py \
    --agent dqn \                    # æ™ºèƒ½ä½“ç±»å‹ï¼š'dqn' æˆ– 'double_dqn'
    --episodes 2000 \                # è®­ç»ƒå›åˆæ•°
    --max_steps 1000 \               # æ¯å›åˆæœ€å¤§æ­¥æ•°
    --eps_start 1.0 \                # åˆå§‹epsilonå€¼
    --eps_end 0.01 \                 # æœ€ç»ˆepsilonå€¼
    --eps_decay 0.995 \              # Epsilonè¡°å‡ç‡
    --target_score 200.0 \           # æ—©åœç›®æ ‡å¹³å‡åˆ†æ•°
    --save_every 500 \               # æ¨¡å‹æ£€æŸ¥ç‚¹é¢‘ç‡
    --model_path models/             # æ¨¡å‹ä¿å­˜ç›®å½•
```

### è¯„ä¼°é€‰é¡¹
```bash
python main_evaluate.py \
    --mode compare \                 # è¯„ä¼°æ¨¡å¼ï¼š'single' æˆ– 'compare'
    --episodes 100 \                 # è¯„ä¼°å›åˆæ•°
    --render \                       # å¯ç”¨ç¯å¢ƒæ¸²æŸ“
    --dqn_model models/dqn_final.pth \
    --ddqn_model models/double_dqn_final.pth
```

## ğŸ§ª å®éªŒç»“æœ

### æ€§èƒ½æŒ‡æ ‡
- **ğŸš€ æ”¶æ•›é€Ÿåº¦**ï¼šé€šå¸¸åœ¨1000-1500å›åˆå†…æ”¶æ•›
- **ğŸ“ˆ æ ·æœ¬æ•ˆç‡**ï¼šé€šè¿‡ç»éªŒå›æ”¾æå‡å­¦ä¹ æ•ˆç‡
- **ğŸ¯ ç¨³å®šæ€§**ï¼šåŒé‡DQNæ˜¾ç¤ºå‡ºæ›´ä½çš„Qå€¼ä¼°è®¡æ–¹å·®
- **âš¡ èµ„æºåˆ©ç”¨ç‡**ï¼šè¾¾åˆ°85-95%çš„æœ€ä¼˜åˆ†é…æ•ˆç‡

### é¢„æœŸç»“æœ
- **ğŸ”„ DQN vs åŒé‡DQN**ï¼šåŒé‡DQNé€šå¸¸æ˜¾ç¤º5-15%çš„æ€§èƒ½æå‡
- **ğŸ“Š å­¦ä¹ æ›²çº¿**ï¼šé€šè¿‡é€‚å½“çš„è¶…å‚æ•°è°ƒä¼˜å®ç°å¹³æ»‘æ”¶æ•›
- **ğŸŒŠ ç¯å¢ƒåŠ¨æ€**ï¼šå¯¹éœ€æ±‚æ¨¡å¼å˜åŒ–çš„è‡ªé€‚åº”å“åº”

## ğŸ”¬ æŠ€æœ¯äº®ç‚¹ä¸åˆ›æ–°

### ç®—æ³•åˆ›æ–°
- **ğŸ§  è¿‡ä¼°è®¡åå·®è§£å†³**ï¼šåŒé‡DQNæœ‰æ•ˆå‡å°‘Qå€¼è¿‡ä¼°è®¡é—®é¢˜
- **ğŸ¯ è‡ªé€‚åº”æ¢ç´¢ç­–ç•¥**ï¼šåŠ¨æ€è°ƒæ•´æ¢ç´¢ä¸åˆ©ç”¨å¹³è¡¡
- **ğŸ“š ç»éªŒå›æ”¾ä¼˜åŒ–**ï¼šé«˜æ•ˆçš„æ ·æœ¬é‡ç”¨æœºåˆ¶

### ç¯å¢ƒè®¾è®¡åˆ›æ–°
- **ğŸŒ å¤šç»´çŠ¶æ€ç©ºé—´**ï¼šç»¼åˆè€ƒè™‘éœ€æ±‚å’Œåˆ†é…çŠ¶æ€
- **âš¡ å®æ—¶å“åº”æœºåˆ¶**ï¼šæ¨¡æ‹ŸçœŸå®ç½‘ç»œç¯å¢ƒçš„åŠ¨æ€ç‰¹æ€§
- **ğŸ® æ™ºèƒ½å¥–åŠ±å‡½æ•°**ï¼šå¹³è¡¡æ•ˆç‡ä¸å…¬å¹³æ€§çš„å¥–åŠ±è®¾è®¡

## ğŸ”¬ ç ”ç©¶åº”ç”¨

### å­¦æœ¯åº”ç”¨åœºæ™¯
- **ğŸ” ç®—æ³•å¯¹æ¯”ç ”ç©¶**ï¼šDQNä¸åŒé‡DQNæ€§èƒ½åˆ†æ
- **ğŸ›ï¸ è¶…å‚æ•°æ•æ„Ÿæ€§**ï¼šè®­ç»ƒå‚æ•°çš„ç³»ç»Ÿæ€§æ¢ç´¢
- **ğŸ—ï¸ ç¯å¢ƒè®¾è®¡**ï¼šè‡ªå®šä¹‰å¼ºåŒ–å­¦ä¹ ç¯å¢ƒå¼€å‘æ¨¡å¼
- **ğŸ”„ è¿ç§»å­¦ä¹ **ï¼šé€‚åº”ä¸åŒèµ„æºåˆ†é…åœºæ™¯

### å·¥ä¸šåº”ç”¨åœºæ™¯
- **ğŸŒ ç½‘ç»œç®¡ç†**ï¼šISPå¸¦å®½åˆ†é…ä¼˜åŒ–
- **â˜ï¸ äº‘è®¡ç®—**ï¼šæ•°æ®ä¸­å¿ƒåŠ¨æ€èµ„æºé…ç½®
- **ğŸ“± ç‰©è”ç½‘ç³»ç»Ÿ**ï¼šè¾¹ç¼˜è®¡ç®—ç¯å¢ƒèµ„æºåˆ†é…
- **âš¡ æ™ºèƒ½ç”µç½‘**ï¼šèƒ½æºåˆ†é…ä¼˜åŒ–
- **ğŸš— æ™ºèƒ½äº¤é€š**ï¼šäº¤é€šæµé‡åŠ¨æ€è°ƒåº¦

## ğŸ“ˆ åˆ†æä¸å¯è§†åŒ–

### å†…ç½®åˆ†æåŠŸèƒ½
- **ğŸ“Š è®­ç»ƒè¿›åº¦**ï¼šå›åˆåˆ†æ•°ã€ç§»åŠ¨å¹³å‡ã€æ”¶æ•›åˆ†æ
- **ğŸ” æ¢ç´¢åŠ¨æ€**ï¼šEpsilonè¡°å‡å¯è§†åŒ–å’Œå½±å“åˆ†æ
- **ğŸŒŠ ç¯å¢ƒè¡Œä¸º**ï¼šéœ€æ±‚æ¨¡å¼å’Œåˆ†é…ç­–ç•¥
- **âš–ï¸ å¯¹æ¯”æ€§èƒ½**ï¼šç®—æ³•é—´ç»Ÿè®¡æ˜¾è‘—æ€§æµ‹è¯•

### æ ¸å¿ƒå±•ç¤ºç¬”è®°æœ¬
ä½äº `notebooks/` ç›®å½•ï¼š
- **ğŸ¯ experiment_analysis.ipynb**ï¼š**æ ¸å¿ƒå±•ç¤ºæ–‡ä»¶** - å®Œæ•´çš„è®­ç»ƒç»“æœåˆ†æå’Œå¯è§†åŒ–

## ğŸ§© æŠ€æœ¯å®ç°

### ç¥ç»ç½‘ç»œæ¶æ„
```python
class DQN(nn.Module):
    def __init__(self, n_observations, n_actions):
        super(DQN, self).__init__()
        self.layer1 = nn.Linear(n_observations, 128)  # è¾“å…¥å±‚åˆ°éšè—å±‚
        self.layer2 = nn.Linear(128, 128)             # éšè—å±‚
        self.layer3 = nn.Linear(128, n_actions)       # è¾“å‡ºå±‚ï¼ˆQå€¼ï¼‰

    def forward(self, x):
        x = F.relu(self.layer1(x))  # ReLUæ¿€æ´»
        x = F.relu(self.layer2(x))  # ReLUæ¿€æ´»
        return self.layer3(x)       # è¾“å‡ºQå€¼
```

### æ ¸å¿ƒç®—æ³•

#### ç»éªŒå›æ”¾æœºåˆ¶
- **ğŸ—ƒï¸ ç¼“å†²åŒºå¤§å°**ï¼šå¯é…ç½®ï¼ˆé»˜è®¤ï¼š100,000ï¼‰
- **ğŸ² é‡‡æ ·ç­–ç•¥**ï¼šå‡åŒ€éšæœºé‡‡æ ·
- **ğŸ”„ æ›´æ–°é¢‘ç‡**ï¼šæ¯4æ­¥æ›´æ–°ä¸€æ¬¡ï¼ˆå¯é…ç½®ï¼‰

#### ç›®æ ‡ç½‘ç»œæ›´æ–°
- **ğŸ”„ è½¯æ›´æ–°**ï¼šÏ„ = 0.001ï¼ˆå¯é…ç½®ï¼‰
- **â° æ›´æ–°é¢‘ç‡**ï¼šæ¯ä¸ªè®­ç»ƒæ­¥éª¤
- **ğŸ¯ ç¨³å®šæ€§**ï¼šé˜²æ­¢ç§»åŠ¨ç›®æ ‡é—®é¢˜

#### æ¢ç´¢ç­–ç•¥
- **ğŸ¯ Îµ-è´ªå©ª**ï¼šå¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨
- **ğŸ“‰ è¡°å‡è®¡åˆ’**ï¼šæŒ‡æ•°è¡°å‡ï¼ˆé»˜è®¤0.995ï¼‰
- **ğŸ”» æœ€å°Îµ**ï¼š0.01ï¼ˆä¿æŒæœ€å°æ¢ç´¢ï¼‰

## ğŸ”§ é«˜çº§é…ç½®

### ç¯å¢ƒè‡ªå®šä¹‰
```python
# è‡ªå®šä¹‰å¥–åŠ±å‡½æ•°ç¤ºä¾‹
def custom_reward(demands, allocations):
    # æœªæ»¡è¶³éœ€æ±‚çš„æƒ©ç½š
    unmet_penalty = np.sum(np.maximum(0, demands - allocations))

    # èµ„æºæµªè´¹çš„æƒ©ç½š
    waste_penalty = np.sum(np.maximum(0, allocations - demands))

    # å¹³è¡¡åˆ†é…çš„å¥–åŠ±
    balance_bonus = -np.std(allocations)

    return -(unmet_penalty + 0.5 * waste_penalty) + balance_bonus
```

### æ™ºèƒ½ä½“è¶…å‚æ•°
```python
agent = DQNAgent(
    state_size=8,           # çŠ¶æ€ç©ºé—´ç»´åº¦
    action_size=5,          # åŠ¨ä½œç©ºé—´å¤§å°
    lr=5e-4,                # å­¦ä¹ ç‡
    buffer_size=100000,     # å›æ”¾ç¼“å†²åŒºå¤§å°
    batch_size=64,          # è®­ç»ƒæ‰¹æ¬¡å¤§å°
    gamma=0.99,             # æŠ˜æ‰£å› å­
    tau=1e-3,               # ç›®æ ‡ç½‘ç»œæ›´æ–°ç‡
    update_every=4,         # å­¦ä¹ é¢‘ç‡
    epsilon=1.0,            # åˆå§‹æ¢ç´¢ç‡
    epsilon_min=0.01,       # æœ€å°æ¢ç´¢ç‡
    epsilon_decay=0.995     # æ¢ç´¢è¡°å‡ç‡
)
```

## ğŸ§ª æµ‹è¯•æ¡†æ¶

### è‡ªåŠ¨åŒ–æµ‹è¯•
```bash
python test_components.py
```

#### æµ‹è¯•è¦†ç›–èŒƒå›´
- **ğŸŒ ç¯å¢ƒåŠŸèƒ½**ï¼šçŠ¶æ€/åŠ¨ä½œç©ºé—´ã€å›åˆæœºåˆ¶
- **ğŸ§  æ¨¡å‹æ¶æ„**ï¼šç½‘ç»œç»“æ„ã€å‰å‘ä¼ æ’­éªŒè¯
- **ğŸ¤– æ™ºèƒ½ä½“è¡Œä¸º**ï¼šåŠ¨ä½œé€‰æ‹©ã€å­¦ä¹ æ›´æ–°
- **ğŸ”— é›†æˆæµ‹è¯•**ï¼šç¯å¢ƒ-æ™ºèƒ½ä½“äº¤äº’
- **ğŸ“Š æ•°æ®æµæ°´çº¿**ï¼šå›æ”¾ç¼“å†²åŒºã€ç»éªŒé‡‡æ ·

## ğŸ“‹ ä¾èµ–è¦æ±‚

### æ ¸å¿ƒä¾èµ–
```
numpy>=1.21.0           # æ•°å€¼è®¡ç®—
pandas>=1.3.0           # æ•°æ®å¤„ç†
matplotlib>=3.4.0       # åŸºç¡€å¯è§†åŒ–
scipy>=1.7.0            # ç§‘å­¦è®¡ç®—
tqdm>=4.62.0            # è¿›åº¦æ¡
gymnasium>=0.29.0       # å¼ºåŒ–å­¦ä¹ ç¯å¢ƒ
torch>=2.0.0            # æ·±åº¦å­¦ä¹ æ¡†æ¶
```

### å¯é€‰ä¾èµ–
```
jupyter>=1.0.0          # ç¬”è®°æœ¬åˆ†æ
seaborn>=0.11.0         # å¢å¼ºå¯è§†åŒ–
tensorboard>=2.8.0      # è®­ç»ƒç›‘æ§
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

### å¼€å‘ç¯å¢ƒè®¾ç½®
```bash
# Forkå¹¶å…‹éš†ä»“åº“
git clone https://github.com/YourUsername/Adaptive-RL-Agent-for-Dynamic-Resource-Allocation.git

# åˆ›å»ºå¼€å‘ç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# å¼€å‘æ¨¡å¼å®‰è£…
pip install -e .
pip install -r requirements-dev.txt
```

### ä»£ç è§„èŒƒ
- **ğŸ¨ æ ¼å¼åŒ–**ï¼šBlackä»£ç æ ¼å¼åŒ–å™¨
- **ğŸ” ä»£ç æ£€æŸ¥**ï¼šflake8æ ·å¼æ£€æŸ¥
- **ğŸ“ ç±»å‹æç¤º**ï¼šé¼“åŠ±ä¸ºæ–°ä»£ç æ·»åŠ ç±»å‹æç¤º
- **ğŸ“š æ–‡æ¡£**ï¼šå®Œæ•´çš„æ–‡æ¡£å­—ç¬¦ä¸²

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ™ è‡´è°¢

- **OpenAI Gymnasium**ï¼šæä¾›å¼ºåŒ–å­¦ä¹ ç¯å¢ƒæ¡†æ¶
- **PyTorchå›¢é˜Ÿ**ï¼šæä¾›æ·±åº¦å­¦ä¹ æ¡†æ¶
- **ç ”ç©¶ç¤¾åŒº**ï¼šæä¾›DQNå’ŒåŒé‡DQNç®—æ³•çš„åŸºç¡€ç†è®º
- **è´¡çŒ®è€…**ï¼šæ‰€æœ‰ä¸ºæœ¬é¡¹ç›®åšå‡ºè´¡çŒ®çš„å¼€å‘è€…

## ğŸ“ è”ç³»æ–¹å¼

- **ğŸ“ ä»“åº“åœ°å€**ï¼š[GitHub](https://github.com/PrescottClub/Adaptive-RL-Agent-for-Dynamic-Resource-Allocation)
- **ğŸ› é—®é¢˜åé¦ˆ**ï¼š[GitHub Issues](https://github.com/PrescottClub/Adaptive-RL-Agent-for-Dynamic-Resource-Allocation/issues)
- **ğŸ’¬ è®¨è®ºäº¤æµ**ï¼š[GitHub Discussions](https://github.com/PrescottClub/Adaptive-RL-Agent-for-Dynamic-Resource-Allocation/discussions)

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. Mnih, V., et al. (2015). Human-level control through deep reinforcement learning. Nature.
2. Van Hasselt, H., et al. (2016). Deep reinforcement learning with double q-learning. AAAI.
3. Schaul, T., et al. (2015). Prioritized experience replay. arXiv preprint.
4. Hessel, M., et al. (2018). Rainbow: Combining improvements in deep reinforcement learning. AAAI.

---

**â­ å¦‚æœæ‚¨è§‰å¾—è¿™ä¸ªé¡¹ç›®æœ‰ç”¨ï¼Œè¯·ç»™æˆ‘ä»¬ä¸€ä¸ªStarï¼**

## ğŸ¯ æ ¸å¿ƒå±•ç¤º

**é‡è¦æé†’**ï¼šæœ¬é¡¹ç›®çš„æ ¸å¿ƒå±•ç¤ºåœ¨ `notebooks/experiment_analysis.ipynb` æ–‡ä»¶ä¸­ï¼ŒåŒ…å«ï¼š
- ğŸ”¬ å®Œæ•´çš„å®éªŒåˆ†æ
- ğŸ“Š è¯¦ç»†çš„æ€§èƒ½å¯¹æ¯”
- ğŸ¨ ä¸°å¯Œçš„å¯è§†åŒ–å›¾è¡¨
- ğŸ“ˆ è®­ç»ƒè¿‡ç¨‹ç›‘æ§
- ğŸ§  ç®—æ³•æ·±åº¦è§£æ

è¯·ç¡®ä¿è¿è¡Œè¯¥ç¬”è®°æœ¬ä»¥æŸ¥çœ‹é¡¹ç›®çš„å®Œæ•´åŠŸèƒ½å±•ç¤ºï¼