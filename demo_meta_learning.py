#!/usr/bin/env python3
"""
å…ƒå­¦ä¹ é©±åŠ¨çš„è‡ªé€‚åº”èµ„æºåˆ†é…ç³»ç»Ÿæ¼”ç¤ºè„šæœ¬

è¿™ä¸ªè„šæœ¬å±•ç¤ºäº†æˆ‘ä»¬åˆ›æ–°çš„å…ƒå­¦ä¹ ç³»ç»Ÿçš„æ ¸å¿ƒåŠŸèƒ½ï¼š
1. å¿«é€Ÿé€‚åº”æ–°ä»»åŠ¡ï¼ˆfew-shot learningï¼‰
2. è·¨åŸŸçŸ¥è¯†è¿ç§»
3. å¤šä»»åŠ¡ç¯å¢ƒç”Ÿæˆ

è¿è¡Œæ–¹å¼ï¼š
python demo_meta_learning.py
"""

import sys
import os
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.append(str(project_root))

try:
    from src.environments.network_traffic_env import DynamicTrafficEnv
    from src.agents.dqn_agent import DQNAgent
    from src.agents.double_dqn_agent import DoubleDQNAgent
    print("âœ… åŸºç¡€æ¨¡å—å¯¼å…¥æˆåŠŸï¼")

    # å°è¯•å¯¼å…¥å…ƒå­¦ä¹ æ¨¡å—
    try:
        from src.environments.meta_task_generator import MetaTaskGenerator, TaskType, MetaEnvironmentWrapper
        from src.agents.meta_dqn_agent import MetaDQNAgent
        from src.utils.meta_trainer import MetaTrainer
        print("âœ… å…ƒå­¦ä¹ æ¨¡å—å¯¼å…¥æˆåŠŸï¼")
        meta_learning_available = True
    except ImportError as e:
        print(f"âš ï¸ å…ƒå­¦ä¹ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        print("å°†ä½¿ç”¨ä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ è¿›è¡Œæ¼”ç¤º")
        meta_learning_available = False

except ImportError as e:
    print(f"âŒ åŸºç¡€æ¨¡å—å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ­¤è„šæœ¬ï¼Œå¹¶å®‰è£…æ‰€éœ€ä¾èµ–")
    sys.exit(1)

def demo_task_generation():
    """æ¼”ç¤ºå¤šä»»åŠ¡ç”Ÿæˆå™¨"""
    if not meta_learning_available:
        print("\nâš ï¸ å…ƒå­¦ä¹ æ¨¡å—ä¸å¯ç”¨ï¼Œè·³è¿‡ä»»åŠ¡ç”Ÿæˆæ¼”ç¤º")
        return None

    print("\n" + "="*60)
    print("ğŸ¯ æ¼”ç¤º1: å¤šä»»åŠ¡ç¯å¢ƒç”Ÿæˆå™¨")
    print("="*60)

    # åˆ›å»ºä»»åŠ¡ç”Ÿæˆå™¨
    generator = MetaTaskGenerator(seed=42)
    
    # ç”Ÿæˆä¸åŒç±»å‹çš„ä»»åŠ¡
    print("\nğŸ“‹ ç”Ÿæˆä¸åŒé¢†åŸŸçš„èµ„æºåˆ†é…ä»»åŠ¡:")
    task_types = [TaskType.NETWORK_TRAFFIC, TaskType.CLOUD_COMPUTING, 
                  TaskType.SMART_GRID, TaskType.VEHICLE_ROUTING]
    
    for i, task_type in enumerate(task_types, 1):
        task = generator.generate_task(task_type=task_type, difficulty=0.6)
        print(f"\n{i}. {task_type.value.upper()}:")
        print(f"   ğŸ“Š èµ„æºæ•°é‡: {task.resource_count}")
        print(f"   ğŸ“ˆ éœ€æ±‚æ¨¡å¼: {task.demand_pattern}")
        print(f"   âš–ï¸ çº¦æŸç±»å‹: {task.constraint_type}")
        print(f"   ğŸšï¸ éš¾åº¦çº§åˆ«: {task.difficulty_level:.2f}")
        print(f"   ğŸ† å¥–åŠ±ç»„ä»¶: {list(task.reward_weights.keys())}")
    
    # ç”Ÿæˆè¯¾ç¨‹å­¦ä¹ åºåˆ—
    print(f"\nğŸ“š ç”Ÿæˆè¯¾ç¨‹å­¦ä¹ åºåˆ—:")
    curriculum = generator.create_curriculum(10, 'linear')
    difficulties = [task.difficulty_level for task in curriculum]
    print(f"   éš¾åº¦èŒƒå›´: {min(difficulties):.2f} â†’ {max(difficulties):.2f}")
    print(f"   ä»»åŠ¡ç±»å‹: {[task.task_type.value[:4] for task in curriculum[:5]]}...")
    
    return generator

def demo_meta_agent():
    """æ¼”ç¤ºå…ƒå­¦ä¹ æ™ºèƒ½ä½“"""
    print("\n" + "="*60)
    print("ğŸ§  æ¼”ç¤º2: å…ƒå­¦ä¹ DQNæ™ºèƒ½ä½“")
    print("="*60)
    
    # åˆ›å»ºå…ƒå­¦ä¹ æ™ºèƒ½ä½“
    agent = MetaDQNAgent(
        state_size=8,
        action_size=10,
        lr=1e-3,
        meta_lr=1e-3,
        adaptation_steps=5,
        seed=42
    )
    
    print(f"\nğŸ¯ æ™ºèƒ½ä½“é…ç½®:")
    print(f"   ğŸ“Š ç½‘ç»œå‚æ•°: {sum(p.numel() for p in agent.meta_network.parameters()):,}")
    print(f"   ğŸ”„ é€‚åº”æ­¥æ•°: {agent.adaptation_steps}")
    print(f"   ğŸ“š å…ƒå­¦ä¹ ç‡: {agent.meta_lr}")
    print(f"   ğŸ® åŠ¨ä½œç©ºé—´: {agent.action_size}")
    
    # æµ‹è¯•ä»»åŠ¡è®¾ç½®
    generator = MetaTaskGenerator(seed=42)
    test_task = generator.generate_task(TaskType.NETWORK_TRAFFIC, difficulty=0.5)
    agent.set_task(test_task)
    
    print(f"\nğŸ¯ è®¾ç½®æµ‹è¯•ä»»åŠ¡: {test_task.task_type.value}")
    print(f"   ğŸ“Š ä»»åŠ¡ç‰¹å¾ç»´åº¦: {agent.task_features.shape}")
    print(f"   ğŸšï¸ ä»»åŠ¡éš¾åº¦: {test_task.difficulty_level:.2f}")
    
    # æµ‹è¯•åŠ¨ä½œé€‰æ‹©
    dummy_state = np.random.rand(8)
    action = agent.act(dummy_state, eps=0.0)
    print(f"   ğŸ® é€‰æ‹©åŠ¨ä½œ: {action}")
    
    return agent, generator

def demo_few_shot_learning(agent, generator):
    """æ¼”ç¤ºå°‘æ ·æœ¬å­¦ä¹ """
    print("\n" + "="*60)
    print("âš¡ æ¼”ç¤º3: å°‘æ ·æœ¬å­¦ä¹ èƒ½åŠ›")
    print("="*60)
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = MetaTrainer(
        agent=agent,
        task_generator=generator,
        base_env_class=DynamicTrafficEnv
    )
    
    # é€‰æ‹©æµ‹è¯•ä»»åŠ¡
    test_task = generator.generate_task(TaskType.CLOUD_COMPUTING, difficulty=0.7)
    print(f"\nğŸ¯ æµ‹è¯•ä»»åŠ¡: {test_task.task_type.value} (éš¾åº¦: {test_task.difficulty_level:.2f})")
    
    # æµ‹è¯•ä¸åŒæ”¯æŒé›†å¤§å°
    support_sizes = [1, 5, 10, 20]
    print(f"\nğŸ“Š æµ‹è¯•ä¸åŒæ”¯æŒé›†å¤§å°: {support_sizes}")
    
    try:
        results = trainer.demonstrate_few_shot_learning(test_task, support_sizes)
        
        print(f"\nğŸ“ˆ å°‘æ ·æœ¬å­¦ä¹ ç»“æœ:")
        for size, result in results.items():
            avg_score = result['avg_score']
            std_score = result['std_score']
            print(f"   æ”¯æŒé›† {size:2d}: {avg_score:6.2f} Â± {std_score:5.2f}")
        
        # è®¡ç®—æ€§èƒ½æå‡
        baseline = results[support_sizes[0]]['avg_score']
        best = results[support_sizes[-1]]['avg_score']
        improvement = (best - baseline) / abs(baseline) * 100
        
        print(f"\nğŸ¯ å…³é”®å‘ç°:")
        print(f"   â€¢ åŸºç¡€æ€§èƒ½ (1æ ·æœ¬): {baseline:.2f}")
        print(f"   â€¢ æœ€ä½³æ€§èƒ½ ({support_sizes[-1]}æ ·æœ¬): {best:.2f}")
        print(f"   â€¢ æ€§èƒ½æå‡: {improvement:+.1f}%")
        
        return results
        
    except Exception as e:
        print(f"âš ï¸ å°‘æ ·æœ¬å­¦ä¹ æ¼”ç¤ºé‡åˆ°é—®é¢˜: {e}")
        print("è¿™æ˜¯æ­£å¸¸çš„ï¼Œå› ä¸ºæˆ‘ä»¬åªæ˜¯åœ¨æ¼”ç¤ºæ¡†æ¶ï¼Œæ²¡æœ‰è¿›è¡Œå®Œæ•´çš„å…ƒè®­ç»ƒ")
        return None

def demo_transfer_learning(agent, generator):
    """æ¼”ç¤ºè·¨åŸŸè¿ç§»å­¦ä¹ """
    print("\n" + "="*60)
    print("ğŸŒ æ¼”ç¤º4: è·¨åŸŸè¿ç§»å­¦ä¹ ")
    print("="*60)
    
    # å®šä¹‰è¿ç§»åœºæ™¯
    scenarios = [
        (TaskType.NETWORK_TRAFFIC, TaskType.CLOUD_COMPUTING, "ç½‘ç»œæµé‡ â†’ äº‘è®¡ç®—"),
        (TaskType.CLOUD_COMPUTING, TaskType.SMART_GRID, "äº‘è®¡ç®— â†’ æ™ºèƒ½ç”µç½‘"),
    ]
    
    print(f"\nğŸ”„ æµ‹è¯•è¿ç§»åœºæ™¯:")
    
    for source_type, target_type, description in scenarios:
        print(f"\n   {description}")
        
        try:
            # åˆ›å»ºæºä»»åŠ¡å’Œç›®æ ‡ä»»åŠ¡
            source_task = generator.generate_task(source_type, difficulty=0.6)
            target_task = generator.generate_task(target_type, difficulty=0.6)
            
            # è®¾ç½®æºä»»åŠ¡
            agent.set_task(source_task)
            source_env = MetaEnvironmentWrapper(DynamicTrafficEnv, source_task)
            
            # æ¨¡æ‹Ÿåœ¨æºä»»åŠ¡ä¸Šçš„å­¦ä¹ 
            print(f"     ğŸ“š åœ¨æºä»»åŠ¡ä¸Šå­¦ä¹ ...")
            source_experiences = []
            for _ in range(10):  # æ”¶é›†å°‘é‡ç»éªŒ
                state, _ = source_env.reset()
                action = agent.act(state, eps=0.3)
                next_state, reward, done, truncated, _ = source_env.step(action)
                source_experiences.append((state, action, reward, next_state, done or truncated))
            
            # å¿«é€Ÿé€‚åº”
            agent.fast_adapt(source_experiences)
            
            # æµ‹è¯•åœ¨ç›®æ ‡ä»»åŠ¡ä¸Šçš„é›¶æ ·æœ¬æ€§èƒ½
            agent.set_task(target_task)
            target_env = MetaEnvironmentWrapper(DynamicTrafficEnv, target_task)
            
            state, _ = target_env.reset()
            action = agent.act(state, eps=0.0)
            next_state, reward, done, truncated, _ = target_env.step(action)
            
            print(f"     ğŸ¯ é›¶æ ·æœ¬è¿ç§»å¥–åŠ±: {reward:.3f}")
            print(f"     âœ… è¿ç§»æµ‹è¯•å®Œæˆ")
            
        except Exception as e:
            print(f"     âš ï¸ è¿ç§»æµ‹è¯•é‡åˆ°é—®é¢˜: {e}")
            print(f"     è¿™æ˜¯æ­£å¸¸çš„ï¼Œæ¡†æ¶æ¼”ç¤ºä¸­çš„ç®€åŒ–å®ç°")

def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸš€ å…ƒå­¦ä¹ é©±åŠ¨çš„è‡ªé€‚åº”èµ„æºåˆ†é…ç³»ç»Ÿ")
    print("ğŸ¯ çªç ´æ€§åˆ›æ–°ï¼šMeta-Learning for Dynamic Resource Allocation")
    print("\nğŸ’¡ æ ¸å¿ƒç‰¹æ€§:")
    print("   â€¢ ğŸ”¥ å¿«é€Ÿé€‚åº”ï¼šä»…éœ€5-10ä¸ªæ ·æœ¬é€‚åº”æ–°ä»»åŠ¡")
    print("   â€¢ ğŸŒ è·¨åŸŸè¿ç§»ï¼šä¸åŒé¢†åŸŸé—´çš„çŸ¥è¯†è¿ç§»")
    print("   â€¢ ğŸ“Š æ™ºèƒ½ç”Ÿæˆï¼šè‡ªåŠ¨ç”Ÿæˆå¤šæ ·åŒ–èµ„æºåˆ†é…åœºæ™¯")
    print("   â€¢ âš¡ å®æ—¶å†³ç­–ï¼šæ¯«ç§’çº§å“åº”æ—¶é—´")
    
    try:
        # æ¼”ç¤º1: ä»»åŠ¡ç”Ÿæˆ
        generator = demo_task_generation()

        if meta_learning_available and generator is not None:
            # æ¼”ç¤º2: å…ƒå­¦ä¹ æ™ºèƒ½ä½“
            agent, generator = demo_meta_agent()

            # æ¼”ç¤º3: å°‘æ ·æœ¬å­¦ä¹ 
            demo_few_shot_learning(agent, generator)

            # æ¼”ç¤º4: è·¨åŸŸè¿ç§»
            demo_transfer_learning(agent, generator)
        else:
            print("\nğŸ”§ æ¼”ç¤ºä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ ç³»ç»Ÿ...")
            # åˆ›å»ºåŸºç¡€ç¯å¢ƒå’Œæ™ºèƒ½ä½“
            env = DynamicTrafficEnv()
            agent = DQNAgent(
                state_size=env.observation_space.shape[0],
                action_size=env.action_space.n,
                seed=42
            )

            print(f"âœ… åˆ›å»ºäº†ä¼ ç»ŸDQNæ™ºèƒ½ä½“")
            print(f"ğŸ“Š çŠ¶æ€ç©ºé—´: {env.observation_space.shape}")
            print(f"ğŸ® åŠ¨ä½œç©ºé—´: {env.action_space.n}")

            # ç®€å•æµ‹è¯•
            state, _ = env.reset()
            action = agent.act(state)
            print(f"ğŸ¯ æ™ºèƒ½ä½“é€‰æ‹©åŠ¨ä½œ: {action}")
        
        print("\n" + "="*60)
        print("ğŸ‰ æ¼”ç¤ºå®Œæˆï¼")
        print("="*60)
        print("\nğŸ† åˆ›æ–°æˆæœæ€»ç»“:")
        print("   âœ… å¤šä»»åŠ¡ç¯å¢ƒç”Ÿæˆå™¨ - è‡ªåŠ¨ç”Ÿæˆå¤šæ ·åŒ–åœºæ™¯")
        print("   âœ… å…ƒå­¦ä¹ DQNæ™ºèƒ½ä½“ - å¿«é€Ÿé€‚åº”æ–°ä»»åŠ¡")
        print("   âœ… å°‘æ ·æœ¬å­¦ä¹ èƒ½åŠ› - å‡ ä¸ªæ ·æœ¬å³å¯å­¦ä¼š")
        print("   âœ… è·¨åŸŸè¿ç§»èƒ½åŠ› - çŸ¥è¯†åœ¨ä¸åŒé¢†åŸŸé—´è¿ç§»")
        
        print(f"\nğŸš€ åº”ç”¨å‰æ™¯:")
        print(f"   â€¢ 5G/6Gç½‘ç»œèµ„æºè°ƒåº¦")
        print(f"   â€¢ äº‘è®¡ç®—å¹³å°æ™ºèƒ½åˆ†é…")
        print(f"   â€¢ æ™ºèƒ½ç”µç½‘è´Ÿè½½å¹³è¡¡")
        print(f"   â€¢ è‡ªåŠ¨é©¾é©¶è½¦é˜Ÿè°ƒåº¦")
        
        print(f"\nğŸ“š è¦æŸ¥çœ‹å®Œæ•´çš„å®éªŒåˆ†æï¼Œè¯·è¿è¡Œ:")
        print(f"   jupyter notebook notebooks/experiment_analysis.ipynb")
        
    except KeyboardInterrupt:
        print(f"\n\nâ¹ï¸ æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\n\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print(f"è¿™å¯èƒ½æ˜¯å› ä¸ºæŸäº›ä¾èµ–æœªå®‰è£…æˆ–ç¯å¢ƒé…ç½®é—®é¢˜")
        print(f"è¯·æ£€æŸ¥ requirements.txt ä¸­çš„ä¾èµ–æ˜¯å¦å·²å®‰è£…")

if __name__ == "__main__":
    main()
